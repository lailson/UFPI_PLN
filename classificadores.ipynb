{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/tr/gp_fznfs2cj3mbthfrrc1rgc0000gn/T/ipykernel_94657/4157135821.py\", line 1, in <module>\n",
      "    import nltk\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/chunk/api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/chunk/util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/__init__.py\", line 84, in <module>\n",
      "    from .base import clone\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 11, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/utils/_chunking.py\", line 8, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 14, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 26, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 11, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/sklearn/utils/fixes.py\", line 24, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/pandas/core/api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/Users/lailson/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/pandas/_libs/__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/projetos/UFPI_PLN/env/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/lailson/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nltk.download(\"names\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros 10 nomes masculinos: ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "Primeiros 10 nomes femininos: ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    }
   ],
   "source": [
    "#Mostar 10 primeiros nomes maculinos e femininos\n",
    "nomes_masculinos = names.words(\"male.txt\")\n",
    "nomes_femininos = names.words(\"female.txt\")\n",
    "\n",
    "print(\"Primeiros 10 nomes masculinos:\", nomes_masculinos[:10])\n",
    "print(\"Primeiros 10 nomes femininos:\", nomes_femininos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de nomes masculinos: 2943\n",
      "Total de nomes femininos: 5001\n"
     ]
    }
   ],
   "source": [
    "#Mostrar tamanho do corpus\n",
    "print(\"Total de nomes masculinos:\", len(nomes_masculinos))\n",
    "print(\"Total de nomes femininos:\", len(nomes_femininos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros 10 nomes rotulados: [('Layton', 'masculino'), ('Demeter', 'feminino'), ('Willette', 'feminino'), ('Vergil', 'masculino'), ('Fiann', 'feminino'), ('Suzann', 'feminino'), ('Guido', 'masculino'), ('Rhianna', 'feminino'), ('Barry', 'feminino'), ('Titus', 'masculino')]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar nomes aleatórios\n",
    "nomes_rotulados = ([(nome, 'masculino') for nome in nomes_masculinos] +\n",
    "                   [(nome, 'feminino') for nome in nomes_femininos])\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(nomes_rotulados)\n",
    "print(\"Primeiros 10 nomes rotulados:\", nomes_rotulados[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ultima_letra': 'n',\n",
       "  'primeira_letra': 'l',\n",
       "  'tamanho_nome': 6,\n",
       "  'duas_ultimas_letras': 'on',\n",
       "  'segunda_letra': 'a',\n",
       "  'duas_primeiras_letras': 'la',\n",
       "  'numero_de_vogais': 2,\n",
       "  'numero_de_consoantes': 4,\n",
       "  'quantidade_letras_repetidas': 0,\n",
       "  'termina_com_vogal': False,\n",
       "  'quantidade_letras_unicas': 6},\n",
       " 'masculino')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Função para extrair features\n",
    "def extrair_features(nome):\n",
    "    features = {\n",
    "        'ultima_letra': nome[-1].lower(),\n",
    "        'primeira_letra': nome[0].lower(),\n",
    "        'tamanho_nome': len(nome),\n",
    "        'duas_ultimas_letras': nome[-2:].lower(),\n",
    "        'segunda_letra': nome[1].lower() if len(nome) > 1 else '',                 \n",
    "        'duas_primeiras_letras': nome[:2].lower(),                                 \n",
    "        'numero_de_vogais': sum(1 for c in nome if c.lower() in 'aeiou'),           \n",
    "        'numero_de_consoantes': sum(1 for c in nome if c.lower() not in 'aeiou'),   \n",
    "        'quantidade_letras_repetidas': sum(nome.lower().count(c) > 1 for c in set(nome.lower())),\n",
    "        'termina_com_vogal': nome[-1].lower() in 'aeiou',                          \n",
    "        'quantidade_letras_unicas': len(set(nome.lower())),                        \n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "conjunto_features = [(extrair_features(nome), genero) for (nome, genero) in nomes_rotulados]\n",
    "conjunto_features[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção de Treino/Teste: 50/50%\n",
      "Acurácia: 0.7784, Precisão: 0.8579, Recall: 0.7761, F1: 0.8150\n",
      "\n",
      "Proporção de Treino/Teste: 60/40%\n",
      "Acurácia: 0.7810, Precisão: 0.8561, Recall: 0.7801, F1: 0.8164\n",
      "\n",
      "Proporção de Treino/Teste: 70/30%\n",
      "Acurácia: 0.7794, Precisão: 0.8581, Recall: 0.7737, F1: 0.8137\n",
      "\n",
      "Proporção de Treino/Teste: 75/25%\n",
      "Acurácia: 0.7835, Precisão: 0.8620, Recall: 0.7771, F1: 0.8173\n",
      "\n",
      "Proporção de Treino/Teste: 80/19%\n",
      "Acurácia: 0.7879, Precisão: 0.8590, Recall: 0.7928, F1: 0.8246\n",
      "\n",
      "Proporção de Treino/Teste: 85/15%\n",
      "Acurácia: 0.7886, Precisão: 0.8611, Recall: 0.7923, F1: 0.8252\n",
      "\n",
      "Proporção de Treino/Teste: 90/9%\n",
      "Acurácia: 0.7962, Precisão: 0.8687, Recall: 0.7956, F1: 0.8305\n",
      "\n",
      "Proporção de Treino/Teste: 95/5%\n",
      "Acurácia: 0.7990, Precisão: 0.8717, Recall: 0.7944, F1: 0.8312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Proporcões\n",
    "proporcoes = [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95] \n",
    "resultados = []\n",
    "\n",
    "for proporcao in proporcoes:\n",
    "    tamanho_treino = int(proporcao * len(conjunto_features))\n",
    "    conjunto_treino, conjunto_teste = conjunto_features[:tamanho_treino], conjunto_features[tamanho_treino:]\n",
    "    \n",
    "    classificador = NaiveBayesClassifier.train(conjunto_treino)\n",
    "    \n",
    "    y_true = [genero for (features, genero) in conjunto_teste]\n",
    "    y_pred = [classificador.classify(features) for (features, genero) in conjunto_teste]\n",
    "    \n",
    "    acuracia = accuracy(classificador, conjunto_teste)\n",
    "    \n",
    "    precisao = precision_score(y_true, y_pred, pos_label='feminino')\n",
    "    recall = recall_score(y_true, y_pred, pos_label='feminino')\n",
    "    f1 = f1_score(y_true, y_pred, pos_label='feminino')\n",
    "    \n",
    "    resultados.append((proporcao, acuracia, precisao, recall, f1))\n",
    "    \n",
    "    print(f\"Proporção de Treino/Teste: {int(proporcao * 100)}/{int((1 - proporcao) * 100)}%\")\n",
    "    print(f\"Acurácia: {acuracia:.4f}, Precisão: {precisao:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a propoção de 95% para treino e 5% para teste tivemos a melhor acurácia de 0.7990.\n",
    "Vamos aplicar a validação cruzada para verificar se a proporção se mantem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proporção de Treino/Teste: 50/50%\n",
      "Acurácia Média: 0.7772\n",
      "Precisão Média: 0.8567\n",
      "Recall Médio: 0.7761\n",
      "F1-Score Médio: 0.8141\n",
      "\n",
      "Proporção de Treino/Teste: 60/40%\n",
      "Acurácia Média: 0.7761\n",
      "Precisão Média: 0.8610\n",
      "Recall Médio: 0.7711\n",
      "F1-Score Médio: 0.8132\n",
      "\n",
      "Proporção de Treino/Teste: 70/30%\n",
      "Acurácia Média: 0.7793\n",
      "Precisão Média: 0.8629\n",
      "Recall Médio: 0.7745\n",
      "F1-Score Médio: 0.8160\n",
      "\n",
      "Proporção de Treino/Teste: 75/25%\n",
      "Acurácia Média: 0.7764\n",
      "Precisão Média: 0.8628\n",
      "Recall Médio: 0.7682\n",
      "F1-Score Médio: 0.8124\n",
      "\n",
      "Proporção de Treino/Teste: 80/19%\n",
      "Acurácia Média: 0.7800\n",
      "Precisão Média: 0.8638\n",
      "Recall Médio: 0.7722\n",
      "F1-Score Médio: 0.8152\n",
      "\n",
      "Proporção de Treino/Teste: 85/15%\n",
      "Acurácia Média: 0.7771\n",
      "Precisão Média: 0.8647\n",
      "Recall Médio: 0.7659\n",
      "F1-Score Médio: 0.8121\n",
      "\n",
      "Proporção de Treino/Teste: 90/9%\n",
      "Acurácia Média: 0.7769\n",
      "Precisão Média: 0.8618\n",
      "Recall Médio: 0.7688\n",
      "F1-Score Médio: 0.8125\n",
      "\n",
      "Proporção de Treino/Teste: 95/5%\n",
      "Acurácia Média: 0.7784\n",
      "Precisão Média: 0.8636\n",
      "Recall Médio: 0.7695\n",
      "F1-Score Médio: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# Avaliação para cada proporção usando K-Fold Cross-Validation\n",
    "for proporcao in proporcoes:\n",
    "    print(f\"\\nProporção de Treino/Teste: {int(proporcao * 100)}/{int((1 - proporcao) * 100)}%\")\n",
    "    \n",
    "    tamanho_treino = int(proporcao * len(conjunto_features))\n",
    "    conjunto_treino = conjunto_features[:tamanho_treino]\n",
    "    conjunto_teste = conjunto_features[tamanho_treino:]\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)  \n",
    "\n",
    "    \n",
    "    acuracias = []\n",
    "    precisoes = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for treino_index, teste_index in kf.split(conjunto_treino):\n",
    "        fold_treino = [conjunto_treino[i] for i in treino_index]\n",
    "        fold_teste = [conjunto_treino[i] for i in teste_index]\n",
    "        classificador = NaiveBayesClassifier.train(fold_treino)\n",
    "\n",
    "        y_true = [genero for (_, genero) in fold_teste]\n",
    "        y_pred = [classificador.classify(features) for (features, _) in fold_teste]\n",
    "\n",
    "        acuracia = accuracy(classificador, fold_teste)\n",
    "        precisao = precision_score(y_true, y_pred, pos_label='feminino')\n",
    "        recall = recall_score(y_true, y_pred, pos_label='feminino')\n",
    "        f1 = f1_score(y_true, y_pred, pos_label='feminino')\n",
    "\n",
    "        acuracias.append(acuracia)\n",
    "        precisoes.append(precisao)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Acurácia Média: {np.mean(acuracias):.4f}\")\n",
    "    print(f\"Precisão Média: {np.mean(precisoes):.4f}\")\n",
    "    print(f\"Recall Médio: {np.mean(recalls):.4f}\")\n",
    "    print(f\"F1-Score Médio: {np.mean(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proporção 70/30 apresentou o melhor acurácia média 0.7793 e também oo melhor f1-score de 0.8160\n",
    "\n",
    "Sem validação cruzada: 95/5\n",
    "Com validação cruzada: 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features mais informativas:\n",
      "Most Informative Features\n",
      "     duas_ultimas_letras = 'na'           femini : mascul =     96.1 : 1.0\n",
      "     duas_ultimas_letras = 'ia'           femini : mascul =     89.8 : 1.0\n",
      "     duas_ultimas_letras = 'la'           femini : mascul =     71.4 : 1.0\n",
      "            ultima_letra = 'a'            femini : mascul =     36.8 : 1.0\n",
      "     duas_ultimas_letras = 'sa'           femini : mascul =     31.4 : 1.0\n",
      "     duas_ultimas_letras = 'ta'           femini : mascul =     31.1 : 1.0\n",
      "            ultima_letra = 'k'            mascul : femini =     29.8 : 1.0\n",
      "     duas_ultimas_letras = 'us'           mascul : femini =     27.4 : 1.0\n",
      "     duas_ultimas_letras = 'ra'           femini : mascul =     25.1 : 1.0\n",
      "     duas_ultimas_letras = 'ch'           mascul : femini =     25.0 : 1.0\n",
      "     duas_ultimas_letras = 'do'           mascul : femini =     25.0 : 1.0\n",
      "     duas_ultimas_letras = 'ld'           mascul : femini =     24.3 : 1.0\n",
      "     duas_ultimas_letras = 'rd'           mascul : femini =     23.2 : 1.0\n",
      "     duas_ultimas_letras = 'rt'           mascul : femini =     22.1 : 1.0\n",
      "   duas_primeiras_letras = 'hu'           mascul : femini =     18.4 : 1.0\n",
      "     duas_ultimas_letras = 'os'           mascul : femini =     18.3 : 1.0\n",
      "            ultima_letra = 'f'            mascul : femini =     15.3 : 1.0\n",
      "     duas_ultimas_letras = 'ea'           femini : mascul =     14.6 : 1.0\n",
      "     duas_ultimas_letras = 'io'           mascul : femini =     14.3 : 1.0\n",
      "     duas_ultimas_letras = 'ka'           femini : mascul =     14.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Mostrar as features mais informativas\n",
    "print(\"\\nFeatures mais informativas:\")\n",
    "classificador.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O gênero previsto para o nome 'Lailson' é: masculino\n"
     ]
    }
   ],
   "source": [
    "nome_novo = \"Lailson\"\n",
    "features_nome_novo = extrair_features(nome_novo)\n",
    "\n",
    "genero_previsto = classificador.classify(features_nome_novo)\n",
    "print(f\"O gênero previsto para o nome '{nome_novo}' é: {genero_previsto}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O gênero previsto para o nome 'Henrique' é: feminino\n"
     ]
    }
   ],
   "source": [
    "nome_novo2 = \"Henrique\"\n",
    "features_nome_novo2 = extrair_features(nome_novo2)\n",
    "\n",
    "genero_previsto = classificador.classify(features_nome_novo2)\n",
    "print(f\"O gênero previsto para o nome '{nome_novo2}' é: {genero_previsto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
