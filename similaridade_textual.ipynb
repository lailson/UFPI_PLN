{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "#Transformando as sentenças em embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"Universidade Federal do Piauí\", \"Processamento de Língua Natural\"]\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape) \n",
    "similaridade = model.similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando como base o site da documentação do HugginFace ( https://www.sbert.net/docs/sentence_transformer/pretrained_models.html ) existem vários modelos originais e modelos da comunidade. \n",
    "\n",
    "1. Modelos originais\n",
    "\n",
    "\n",
    " São modelos que utilizam SetenceTransformer para gerar embeddings gerais de sentenças e consultas. Os modelos da família all-*, treinados em mais de 1 bilhão parametros. Esse modelo all-mpnet-base-v2 mapeia frases e parágrafos para um espaço vetorial de 768 dimensões e pode ser usado para tarefas como agrupamento ou pesquisa semântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade semântica: 0.5479925870895386\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "frase_1 = model.encode(\"O gato está no telhado\")\n",
    "frase_2 = model.encode(\"Um felino está sobre o teto da casa\")\n",
    "similaridade = util.cos_sim(frase_1, frase_2)\n",
    "print(f\"Similaridade semântica: {similaridade.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos originais são capazes de gerar bons embeddings e no código acima geramos o embedding da frase 1 e da frase 2 e ao final foi feito a similiradide do coseno para buscar a proximidade entre os vatores em busca de uma similaridade entre as fraes. Antes de olhar o resultado podemos ver que apesa das duas frases não terem nenhuma palavra repetida, ou seja, uma palavra de uma frase esta contida na outra frase você pode perceber que o significado permanece o mesmo, ou bem similar, ja que eu apenas troque a palavra mantgendo o singificado, ou seja, eu fiz a substituição de palavras por sinônimos, em vez de \"gato\" utilizei \"felino\", em vez de \"telhado\" eu utilizei \"teto da casa\". Ao visualizar o resutlado de similaridade um resultado de 0.54 em uma escala que vai de -1 (sentido oposto), passando por 0 (não tem relação) até 1 que seria exatamente similar, ou seja, mesma frase, podemos perceber que não foi um resutlado satisfatório. Ao visualilzar detalhes do modelo temos que ele tem modelo base microsoft/mpnet-base, tem uma dimensão de 768, ou seja, cada vetor de embedding tem 768 valores, utiilzou tecnica de agregação chamda mean pooling e foi treina com mais de 1 bilhão de parametros, então era para dar um resultado melhor. Ao entrar nesse link do [modelo](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) podemos ver os datasets que foi utilizado como treino, como a base do reddit, citacoes do s2orc, respostas do wikipedia, entre outros. Assim a base utilizada foi o ingles, então vamos alterar o código e utilizar frases em ingles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade semântica: 0.8366097807884216\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "frase_1 = model.encode(\"The cat is on the roof\")\n",
    "frase_2 = model.encode(\"A feline is on top of the house roof\")\n",
    "\n",
    "similaridade = util.cos_sim(frase_1, frase_2)\n",
    "print(f\"Similaridade semântica: {similaridade.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que o valor agora foi para 0.83 que é próximo de 1, agora faz sentido!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Semantic Search Models\n",
    "\n",
    "Modelos otimizados para busca semântica, projetados para encontrar passagens relevantes com base em uma consulta. O base model são modelos gerais que não foram ajustados para tarefas específicas, foram treinados de forma ampla para aprender representações de linguagem natural, como a relação contextual entre palavras e frases, ja os modelos de Semantic Search são modelos ajustados especificamente para tarefas de busca semântica, onde o objetivo é encontrar passagens de texto relevantes em resposta a uma consulta. Exemplos de uso: Sistemas de recuperação de documentos, FAQs, busca de respostas em grandes bancos de dados textuais.\n",
    "\n",
    "Vamos simular um FAQ com o model multi-qa-mpnet-base-cos-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta do usuário: Esqueci minha senhja, como posso recuperar?\n",
      "Resposta mais relevante: Para redefinir sua senha, acesse as configurações da conta e clique em 'Esqueci minha senha'. Siga as instruções enviadas ao seu e-mail.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\")\n",
    "\n",
    "consulta = \"Esqueci minha senhja, como posso recuperar?\"\n",
    "embedding_consulta = model.encode(consulta)\n",
    "\n",
    "faq_perguntas = [\n",
    "    \"Como faço para redefinir minha senha?\",\n",
    "    \"Quais métodos de pagamento são aceitos?\",\n",
    "    \"Como posso rastrear meu pedido?\",\n",
    "    \"Qual é o horário de atendimento ao cliente?\",\n",
    "    \"Vocês oferecem reembolso?\",\n",
    "]\n",
    "\n",
    "faq_respostas = [\n",
    "    \"Para redefinir sua senha, acesse as configurações da conta e clique em 'Esqueci minha senha'. Siga as instruções enviadas ao seu e-mail.\",\n",
    "    \"Aceitamos pagamentos via cartão de crédito, PayPal e transferência bancária.\",\n",
    "    \"Após o envio do pedido, você receberá um e-mail com o código de rastreamento e um link para acompanhar sua entrega.\",\n",
    "    \"Nosso atendimento está disponível de segunda a sexta, das 9h às 18h.\",\n",
    "    \"Sim, oferecemos reembolso para produtos devolvidos em até 30 dias após a compra, desde que estejam em boas condições.\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(faq_perguntas)\n",
    "\n",
    "similarity = model.similarity(embedding_consulta, embeddings)\n",
    "\n",
    "indice_mais_similar = similarity.argmax()\n",
    "resposta_encontrada = faq_respostas[indice_mais_similar]\n",
    "\n",
    "print(f\"Pergunta do usuário: {consulta}\")\n",
    "print(f\"Resposta mais relevante: {resposta_encontrada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso é feito o embedding da pergunta (consulta) e o embedding de cada pergunta da FAQ, depois com o similarity ele busca a similaridade com as perguntas do FAQ, como ele retorna o indice da pergunta então utilize esse paga pegar a resposta correspondente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Multi-QA Models\n",
    "\n",
    "Os modelos Multi-QA são modelos treinados para realizar buscas sem6anticas usando grandes volumes de dados de perguntas e respotas (QA). \n",
    "\n",
    "- multi-qa-mpnet-base-dot-v1 e multi-qa-mpnet-base-cos-v1: Esses modelos utilizam a arquitetura MPNet e fornecem alta precisão, sendo os mais indicados para tarefas em que a qualidade de busca é prioridade.\n",
    "-\tmulti-qa-distilbert-dot-v1 e multi-qa-distilbert-cos-v1: Versões menores baseadas em DistilBERT, oferecendo um bom equilíbrio entre desempenho e velocidade.\n",
    "-\tmulti-qa-MiniLM-L6-dot-v1 e multi-qa-MiniLM-L6-cos-v1: Esses modelos MiniLM são os mais rápidos em processamento de consultas, ideais para aplicações em tempo real que precisam de um alto número de consultas por segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade entre a consulta e as passagens do FAQ:\n",
      "tensor([[0.6782, 0.4743, 0.3694]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"multi-qa-distilbert-dot-v1\")\n",
    "\n",
    "consulta = \"Como posso redefinir minha senha?\"\n",
    "query_embedding = model.encode(consulta)\n",
    "\n",
    "faq_perguntas = [\n",
    "    \"Para redefinir sua senha, vá até as configurações e selecione 'Esqueci minha senha'.\",\n",
    "    \"Aceitamos cartão de crédito, PayPal e transferências bancárias.\",\n",
    "    \"Você pode rastrear seu pedido através do link de rastreamento fornecido em seu e-mail.\"\n",
    "]\n",
    "\n",
    "passage_embeddings = model.encode(faq_perguntas)\n",
    "\n",
    "similaridade = util.cos_sim(query_embedding, passage_embeddings)\n",
    "\n",
    "print(\"Similaridade entre a consulta e as passagens do FAQ:\")\n",
    "print(similaridade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizei o modelo multi-qa-distilbert-dot-v1 que são versões menores e oferece um bom equilíbrio entre eficiencia e desempenho. Podemos notar que a execução desse código doi levemente mais rápido do que o anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilingual Models\n",
    "\n",
    "São modelos projetados para gerar embeddings semelhantes para o mesmo texto em diferentes idiomas, sem a necessidade de especificar o idioma de entrada. Isso significa que, independentemente do idioma, textos que transmitem a mesma mensagem ou significado terão embeddings semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade entre frases em diferentes idiomas:\n",
      "tensor([[1.0000, 0.9863, 0.8716, 0.9882, 0.9871],\n",
      "        [0.9863, 1.0000, 0.9012, 0.9902, 0.9903],\n",
      "        [0.8716, 0.9012, 1.0000, 0.8931, 0.9077],\n",
      "        [0.9882, 0.9902, 0.8931, 1.0000, 0.9887],\n",
      "        [0.9871, 0.9903, 0.9077, 0.9887, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
    "\n",
    "frases = [\n",
    "    \"How are you?\",           # Inglês\n",
    "    \"¿Cómo estás?\",           # Espanhol\n",
    "    \"Comment ça va?\",         # Francês\n",
    "    \"Wie geht es dir?\",       # Alemão\n",
    "    \"Como você está?\"         # Português\n",
    "]\n",
    "\n",
    "embeddings = model.encode(frases)\n",
    "\n",
    "similaridade = util.cos_sim(embeddings, embeddings)\n",
    "print(\"Similaridade entre frases em diferentes idiomas:\")\n",
    "print(similaridade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa matriz de similiaridade mostra o quão próximo estão no espaço vetorial mesmo sendo palavras em idiomas distintos. A frase \"How are you?\" tem similaridade 1 com ela mesmo, o que faz sentido ja que são a mesma frase, ela também sem similaridade 0.9863 (aproximadamente 1) com \"¿Cómo estás?\" que é o mesmo sentido só que em espanhl, e assim por diante "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Image & Text-Models\n",
    "\n",
    "São modelos de deep learning capazes de representar iamgens e textos em um espaço vetorial comum. Isso significa que tnato imagens quanto stextos são mapeados para a mesma \"linguagem\" matemática, possibilitando a comparação e a semelehança entre eles. Vamos utilizar a imagens de dois cachorros na neve\n",
    "\n",
    "![Dois cachorros na neve](./img/two_dogs_in_snow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3069, 0.1010, 0.1086]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "\n",
    "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "img_emb = model.encode(Image.open(\"img/two_dogs_in_snow.png\"))\n",
    "\n",
    "text_emb = model.encode(\n",
    "    [\"Two dogs in the snow\", \"A cat on a table\", \"A picture of London at night\"]\n",
    ")\n",
    "\n",
    "similarity_scores = model.similarity(img_emb, text_emb)\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os INSTRUCTOR Models são uma categoria especial de modelos projetados para seguir instruções específicas durante o processo de criação de embeddings, tornando-os úteis em tarefas que exigem uma interpretação contextualizada e orientada. Diferente dos modelos normais de Sentence Transformers, os INSTRUCTOR Models são treinados com um enfoque em instruções dadas explicitamente, o que permite a geração de embeddings de acordo com o contexto e a tarefa definidas pela instrução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 768)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"hkunlp/instructor-large\")\n",
    "embeddings = model.encode(\n",
    "    [\n",
    "        \"Dynamical Scalar Degree of Freedom in Horava-Lifshitz Gravity\",\n",
    "        \"Comparison of Atmospheric Neutrino Flux Calculations at Low Energies\",\n",
    "        \"Fermion Bags in the Massive Gross-Neveu Model\",\n",
    "        \"QCD corrections to Associated t-tbar-H production at the Tevatron\",\n",
    "    ],\n",
    "    prompt=\"Represent the Medicine sentence for clustering: \",\n",
    ")\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os Instrucotr Models geram embeddings ajustados para uma determinada ação/frase. No nosso exemplo a instrução ou prompt é usada para orientar o modelo a gerar embeddings com um foco particular em \"sentenças de medicina para agrupamento\" (medicine sentence for clustering) — embora os textos sejam de temas variados e científicos. \n",
    "\n",
    " prompt=\"Represent the Medicine sentence for clustering: \" isso sugere que o modelo deve interpretar cada frase científica fornecida como se ela estivesse relacionada à área médica e criar embeddings para fins de “clustering” (agrupamento) nesse contexto mesmo que as frases fornecidas não sejam especificamente sobre medicina, o prompt instrui o modelo a gerar embeddings que talvez pudessem ser úteis para tarefas relacionadas à medicina ou ao agrupamento de informações científicas em um contexto médico.\n",
    "\n",
    " Essa abordagem de codificação adiciona um viés ao embedding, fazendo com que ele capture informações de maneira que seja útil para tarefas específicas — neste caso, para agrupamento no contexto de medicina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação entre Sentence Embeddings, Transformer sem usar sentece Embedding s e Similariade com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Sentence Embeddings: 0.8263471126556396\n"
     ]
    }
   ],
   "source": [
    "# Sentence Embedding\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')  #Modelo base nao funcionou legal pq funciona apenas em ingles\n",
    "\n",
    "frases = [\"O gato está no tapete.\", \"O felino está em cima do carpete.\"]\n",
    "embeddings = model.encode(frases)\n",
    "\n",
    "similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
    "print(f\"Similaridade Sentence Embeddings: {similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Transformers: 0.8272312879562378\n"
     ]
    }
   ],
   "source": [
    "# Transformers sem usar sentence Embeddings\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(frases, return_tensors='pt', padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "embeddings = torch.mean(outputs.last_hidden_state, dim=1) # Pooling: média das representações de tokens\n",
    "\n",
    "similaridade = F.cosine_similarity(embeddings[0], embeddings[1], dim=0)\n",
    "print(f\"Similaridade Transformers: {similaridade.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install spacy\n",
    "! python -m spacy download pt_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade SpaCy: 0.8976613572535077\n"
     ]
    }
   ],
   "source": [
    "#Spacy\n",
    "import spacy\n",
    "\n",
    "pln = spacy.load('pt_core_news_md')\n",
    "\n",
    "doc1 = pln(\"O gato está no tapete.\")\n",
    "doc2 = pln(\"O felino está em cima do carpete.\")\n",
    "\n",
    "similarity = doc1.similarity(doc2)\n",
    "print(f\"Similaridade SpaCy: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerar uma aplicação que utilize similaridade semântica em um determinado contexto, por exemplo, \n",
    "1.  correção automática de questões discursivas: gabarito x respostas dos alunos; \n",
    "2.  escolha de candidatos a uma determinada vaga: perfil desejado do candidato x perfil obtido nos dados do currículo lattes, linkedin, ou outra RSO; \n",
    "3.  analisar se uma pergunta já foi feita: pergunta do usuário x perguntas realizadas em um Q&A system; entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do Aluno 1: Aprendizado supervisionado é um método de machine learning onde o modelo é treinado com um conjunto de dados rotulado, ou seja, onde as entradas e saídas desejadas são fornecidas. O objetivo é que o modelo aprenda a mapear as entradas para as saídas corretas, podendo generalizar para novos dados.\n",
      "Similaridade: 1.0000\n",
      "Nota: 1.0\n",
      "\n",
      "Resposta do Aluno 2: Aprendizado supervisionado é quando um modelo é treinado com dados que possuem as respostas corretas, permitindo que ele aprenda a partir desses dados.\n",
      "Similaridade: 0.7983\n",
      "Nota: 0.5\n",
      "\n",
      "Resposta do Aluno 3: Aprendizado supervisionado é um tipo de machine learning em que o modelo decide por si mesmo o que deve aprender sem receber nenhum tipo de resposta ou dado rotulado.\n",
      "Similaridade: 0.8389\n",
      "Nota: 0.5\n",
      "\n",
      "Resposta do Aluno 4: Aprendizado supervisionado é quando o professor fica supervisionando\n",
      "Similaridade: 0.6378\n",
      "Nota: 0.5\n",
      "\n",
      "Resposta do Aluno 5: 2+ 2 = 4\n",
      "Similaridade: 0.1115\n",
      "Nota: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Correção automática de questão discursiva\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "gabarito = \"Aprendizado supervisionado é um método de machine learning onde o modelo é treinado com um conjunto de dados rotulado, ou seja, onde as entradas e saídas desejadas são fornecidas. O objetivo é que o modelo aprenda a mapear as entradas para as saídas corretas, podendo generalizar para novos dados.\"\n",
    "\n",
    "respostas_alunos = [\n",
    "    \"Aprendizado supervisionado é um método de machine learning onde o modelo é treinado com um conjunto de dados rotulado, ou seja, onde as entradas e saídas desejadas são fornecidas. O objetivo é que o modelo aprenda a mapear as entradas para as saídas corretas, podendo generalizar para novos dados.\",  # Resposta correta\n",
    "    \"Aprendizado supervisionado é quando um modelo é treinado com dados que possuem as respostas corretas, permitindo que ele aprenda a partir desses dados.\",  # Resposta parcial\n",
    "    \"Aprendizado supervisionado é um tipo de machine learning em que o modelo decide por si mesmo o que deve aprender sem receber nenhum tipo de resposta ou dado rotulado.\",  # Resposta incorreta\n",
    "    \"Aprendizado supervisionado é quando o professor fica supervisionando\", #errada\n",
    "    \"2+ 2 = 4\"\n",
    "]\n",
    "\n",
    "embedding_gabarito = model.encode(gabarito)\n",
    "embeddings_respostas = model.encode(respostas_alunos)\n",
    "\n",
    "similaridades = [util.cos_sim(embedding_gabarito, resposta).item() for resposta in embeddings_respostas]\n",
    "\n",
    "notas = []\n",
    "for similaridade in similaridades:\n",
    "    if similaridade >= 0.85:\n",
    "        nota = 1.0  \n",
    "    elif 0.5 <= similaridade < 0.85:\n",
    "        nota = 0.5  \n",
    "    else:\n",
    "        nota = 0.0  \n",
    "    notas.append(nota)\n",
    "\n",
    "for i, (resposta, similaridade, nota) in enumerate(zip(respostas_alunos, similaridades, notas)):\n",
    "    print(f\"Resposta do Aluno {i+1}: {resposta}\\nSimilaridade: {similaridade:.4f}\\nNota: {nota}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfil do Candidato 1: Engenheiro de machine learning com 5 anos de experiência em Python e desenvolvimento de modelos preditivos. Experiência em plataformas de computação em nuvem e implantação de soluções de machine learning.\n",
      "Similaridade: 0.7847 (Perfil Contratado)\n",
      "\n",
      "Perfil do Candidato 2: Cientista de dados com experiência em Python e estatísticas, com conhecimento em modelos de machine learning. Experiência com dados na nuvem e análise preditiva.\n",
      "Similaridade: 0.6264\n",
      "\n",
      "Perfil do Candidato 3: Desenvolvedor de software com foco em front-end, experiência em JavaScript, HTML e CSS. Interesse em aprender mais sobre machine learning.\n",
      "Similaridade: 0.5244\n",
      "\n",
      "Perfil do Candidato 4: Desenvolvedor front-end, html, css, javascript, angular, react\n",
      "Similaridade: 0.1096\n",
      "\n",
      "Perfil Contratado:\n",
      "Engenheiro de machine learning com 5 anos de experiência em Python e desenvolvimento de modelos preditivos. Experiência em plataformas de computação em nuvem e implantação de soluções de machine learning.\n"
     ]
    }
   ],
   "source": [
    "# Sistema para match de perfil de linkedin\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "perfil_desejado = \"Procuramos um engenheiro de machine learning com experiência em Python, modelagem preditiva, e habilidades em cloud computing para desenvolvimento de soluções escaláveis.\"\n",
    "\n",
    "perfis_candidatos = [\n",
    "    \"Engenheiro de machine learning com 5 anos de experiência em Python e desenvolvimento de modelos preditivos. Experiência em plataformas de computação em nuvem e implantação de soluções de machine learning.\",  # Alta similaridade\n",
    "    \"Cientista de dados com experiência em Python e estatísticas, com conhecimento em modelos de machine learning. Experiência com dados na nuvem e análise preditiva.\",  # Similaridade média\n",
    "    \"Desenvolvedor de software com foco em front-end, experiência em JavaScript, HTML e CSS. Interesse em aprender mais sobre machine learning.\" , # Baixa similaridade\n",
    "    \"Desenvolvedor front-end, html, css, javascript, angular, react\" #Perfil sem similaridade\n",
    "]\n",
    "\n",
    "embedding_perfil_desejado = model.encode(perfil_desejado)\n",
    "embeddings_candidatos = model.encode(perfis_candidatos)\n",
    "similaridades = [util.cos_sim(embedding_perfil_desejado, embedding_candidato).item() for embedding_candidato in embeddings_candidatos]\n",
    "\n",
    "indice_candidato_contratado = similaridades.index(max(similaridades))\n",
    "\n",
    "for i, (perfil, similaridade) in enumerate(zip(perfis_candidatos, similaridades)):\n",
    "    status = \" (Perfil Contratado)\" if i == indice_candidato_contratado else \"\"\n",
    "    print(f\"Perfil do Candidato {i+1}: {perfil}\\nSimilaridade: {similaridade:.4f}{status}\\n\")\n",
    "\n",
    "perfil_contratado = perfis_candidatos[indice_candidato_contratado]\n",
    "print(f\"Perfil Contratado:\\n{perfil_contratado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta semelhante encontrada: 'Como posso recuperar minha senha esquecida?'\n",
      "Similaridade: 0.7982\n",
      "\n",
      "Pergunta semelhante encontrada: 'Como fazer para redefinir a senha da minha conta?'\n",
      "Similaridade: 0.7546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analisar se uma pergunta foi feita: pergunta do usuário x perguntas realizadas em um QA\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "pergunta_usuario = \"Como posso resetar minha senha?\"\n",
    "\n",
    "perguntas_anteriores = [\n",
    "    \"Como posso recuperar minha senha esquecida?\",\n",
    "    \"Quais métodos de pagamento são aceitos no sistema?\",\n",
    "    \"Como alterar meu endereço cadastrado?\",\n",
    "    \"Qual é o horário de atendimento ao cliente?\",\n",
    "    \"Como fazer para redefinir a senha da minha conta?\"\n",
    "]\n",
    "\n",
    "embedding_pergunta_usuario = model.encode(pergunta_usuario)\n",
    "embeddings_perguntas_anteriores = model.encode(perguntas_anteriores)\n",
    "\n",
    "similaridades = [util.cos_sim(embedding_pergunta_usuario, pergunta).item() for pergunta in embeddings_perguntas_anteriores]\n",
    "\n",
    "limiar_similaridade = 0.75\n",
    "\n",
    "pergunta_ja_feita = False\n",
    "for i, similaridade in enumerate(similaridades):\n",
    "    if similaridade >= limiar_similaridade:\n",
    "        print(f\"Pergunta semelhante encontrada: '{perguntas_anteriores[i]}'\")\n",
    "        print(f\"Similaridade: {similaridade:.4f}\\n\")\n",
    "        pergunta_ja_feita = True\n",
    "\n",
    "if not pergunta_ja_feita:\n",
    "    print(\"Pergunta inédita, adicione ao sistema de Q&A.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dois textos podem ser similares apesar de não ter uma única palavra em comum?\n",
    "DICA: Utilize os métodos de similaridade semântica discutidos em sala de aula para\n",
    "responder à pergunta, considerando textos pequenos (até 5 palavras) e textos\n",
    "médios (até 400 palavras).\n",
    "\n",
    "R= Sim, mostramos nos códigos acimas que o embedding é a representação matemática de um texto (palavra, frase ou texto-doc), assim é possível fazer calculos com essa representação, um desses calculos é justamente a diferença entre esses dois vetores, quando menor a diferença maios próximos esses vetores estão, isso mostra a similaridade, ou seja, quando mais próximo mais similar/relacionado sÃo esses dois textos, assim diferente de uma bsuca SQL, a busca por similaridade não querer que os textos tenham as mesmas pakavras, para que eles sejam similares precisam ter sentidos próximos, para isso podemos utilizar, por exemplos, sinônimos. Podemos demostrar com o texto do gato que colocamos no exemplo de busca semantica: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade semântica: 0.8588588237762451\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "frase_1 = model.encode(\"O gato está no telhado\")\n",
    "frase_2 = model.encode(\"Um felino está sobre o teto da casa\")\n",
    "\n",
    "similaridade = util.cos_sim(frase_1, frase_2)\n",
    "print(f\"Similaridade semântica: {similaridade.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos utilizar exemplos maiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/lailson/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto 1 : The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place . The jury further said in term-end present...\n",
      "Texto 2 : under fire for its practices in the appointment of appraisers , guardians and administrators and the awarding of fees and compensation . Wards protected The jury said it found the court `` has incorpo...\n",
      "Similaridade entre textos: 0.6323\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown  \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def calcular_similaridade(texto1, texto2):\n",
    "    embedding1 = model.encode(texto1)\n",
    "    embedding2 = model.encode(texto2)\n",
    "    similaridade = util.cos_sim(embedding1, embedding2).item()\n",
    "    return similaridade\n",
    "\n",
    "texto_medio1 = \" \".join(brown.words()[:400])\n",
    "texto_medio2 = \" \".join(brown.words()[500:900])\n",
    "similaridade_medio = calcular_similaridade(texto_medio1, texto_medio2)\n",
    "\n",
    "\n",
    "print(f\"Texto 1 : {texto_medio1[:200]}...\")  \n",
    "print(f\"Texto 2 : {texto_medio2[:200]}...\") \n",
    "print(f\"Similaridade entre textos: {similaridade_medio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
