{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./env/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./env/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./env/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.12/site-packages (from nltk) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 21:03:20.902 python[1342:12359] +[IMKClient subclass]: chose IMKClient_Legacy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [('eu sou admirada por muitos','alegria'),\n",
    "        ('me sinto completamente amado','alegria'),\n",
    "        ('amar e maravilhoso','alegria'),\n",
    "        ('estou me sentindo muito animado novamente','alegria'),\n",
    "        ('eu estou muito bem hoje','alegria'),\n",
    "        ('que belo dia para dirigir um carro novo','alegria'),\n",
    "        ('o dia est· muito bonito','alegria'),\n",
    "        ('estou contente com o resultado do teste que fiz no dia de ontem','alegria'),\n",
    "        ('o amor e lindo','alegria'),\n",
    "        ('nossa amizade e amor vai durar para sempre', 'alegria'),\n",
    "        ('estou amedrontado', 'medo'),\n",
    "        ('ele esta me ameacando a dias', 'medo'),\n",
    "        ('isso me deixa apavorada', 'medo'),\n",
    "        ('este lugar e apavorante', 'medo'),\n",
    "        ('se perdermos outro jogo seremos eliminados e isso me deixa com pavor', 'medo'),\n",
    "        ('tome cuidado com o lobisomem', 'medo'),\n",
    "        ('se eles descobrirem estamos encrencados', 'medo'),\n",
    "        ('estou tremendo de medo', 'medo'),\n",
    "        ('eu tenho muito medo dele', 'medo'),\n",
    "        ('estou com medo do resultado dos meus testes', 'medo')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção das stop word \n",
    "# palavras que não tem um significado, não tem relevância para o sentido\n",
    "# é interessante retirar pois pode influenciar negativamente o algoritmo \n",
    "# Ajuda a diminuir a dimensionalidade dos dados tambem\n",
    "# Vamos criar uma lista de stopwords\n",
    "\n",
    "stopwords = ['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do', 'e', 'estou', 'esta', 'esta', 'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa', 'o', 'outro', 'para', 'que', 'sem', 'talvez', 'tem', 'tendo','tenha', 'teve', 'tive', 'todo', 'um', 'uma', 'umas', 'uns', 'vou']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "#stopwordsnltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texto):\n",
    "    frases = []\n",
    "    for (palavras, emocao) in texto:\n",
    "        semstop = [p for p in palavras.split() if p.lower() not in stopwordsnltk]\n",
    "        frases.append((' '.join(semstop), emocao))\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('admirada muitos', 'alegria'),\n",
       " ('sinto completamente amado', 'alegria'),\n",
       " ('amar maravilhoso', 'alegria'),\n",
       " ('sentindo animado novamente', 'alegria'),\n",
       " ('bem hoje', 'alegria'),\n",
       " ('belo dia dirigir carro novo', 'alegria'),\n",
       " ('dia est· bonito', 'alegria'),\n",
       " ('contente resultado teste fiz dia ontem', 'alegria'),\n",
       " ('amor lindo', 'alegria'),\n",
       " ('amizade amor vai durar sempre', 'alegria'),\n",
       " ('amedrontado', 'medo'),\n",
       " ('ameacando dias', 'medo'),\n",
       " ('deixa apavorada', 'medo'),\n",
       " ('lugar apavorante', 'medo'),\n",
       " ('perdermos outro jogo eliminados deixa pavor', 'medo'),\n",
       " ('tome cuidado lobisomem', 'medo'),\n",
       " ('descobrirem encrencados', 'medo'),\n",
       " ('tremendo medo', 'medo'),\n",
       " ('medo', 'medo'),\n",
       " ('medo resultado testes', 'medo')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_sem_stopword = remove_stopwords(base)\n",
    "base_sem_stopword\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração do radical das palavras (Stemming)\n",
    "# Também server para diminuir a dimencionalidade dos dados\n",
    "# Exemplo\n",
    "# Livr - o\n",
    "# Livr - inho\n",
    "# Livr - eiro\n",
    "# Livr - eco\n",
    "# Note que o radical é Livr \n",
    "# Outro exemplo \n",
    "# inter   - nacion  - al \n",
    "# prefixo - radical - sufixo\n",
    "# perceba que ao extrair apenas o radical das palavras teremos um redução da dimencionalidade\n",
    "\n",
    "def aplicastemmer(texto):\n",
    "    stemmer = nltk.stem.RSLPStemmer() #Português \n",
    "    frasessteming = []\n",
    "    for (palavras, emocao ) in texto:\n",
    "        comsteming = [str(stemmer.stem(p)) for p in palavras.split()  if p not in stopwordsnltk ]\n",
    "        frasessteming.append((comsteming, emocao))\n",
    "    return frasessteming\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['admir', 'muit'], 'alegria'),\n",
       " (['sint', 'complet', 'am'], 'alegria'),\n",
       " (['am', 'maravilh'], 'alegria'),\n",
       " (['sent', 'anim', 'nov'], 'alegria'),\n",
       " (['bem', 'hoj'], 'alegria'),\n",
       " (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'),\n",
       " (['dia', 'est·', 'bonit'], 'alegria'),\n",
       " (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'),\n",
       " (['am', 'lind'], 'alegria'),\n",
       " (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'),\n",
       " (['amedront'], 'medo'),\n",
       " (['ameac', 'dia'], 'medo'),\n",
       " (['deix', 'apavor'], 'medo'),\n",
       " (['lug', 'apavor'], 'medo'),\n",
       " (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'),\n",
       " (['tom', 'cuid', 'lobisom'], 'medo'),\n",
       " (['descobr', 'encrenc'], 'medo'),\n",
       " (['trem', 'med'], 'medo'),\n",
       " (['med'], 'medo'),\n",
       " (['med', 'result', 'test'], 'medo')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frasescomsteming = aplicastemmer(base)\n",
    "frasescomsteming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos ver que nossa base agora tem apenas o radical, palavras como amado ou amar agora tem o mesmo radical : am\n",
    "# outro exemplo seria o novamente e novo, as duas palavras tem o mesmo radical : nov. Nesse caso são duas palavras com sentidos distintos com o mesmo radical. Esse é aspecto negativo dessa técnica \n",
    "# Depois de aplicar essas duas técnicas agora iremos fazer a listagem de todas as palavras\n",
    "\n",
    "def busca_palavras(frases):\n",
    "    todas_as_palavras = []\n",
    "    for (palavras, emocao) in frases: \n",
    "        todas_as_palavras.extend(palavras)\n",
    "    return todas_as_palavras\n",
    "\n",
    "palavras = busca_palavras(frasescomsteming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admir', 'muit', 'sint', 'complet', 'am', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'nov', 'dia', 'est·', 'bonit', 'cont', 'result', 'test', 'fiz', 'dia', 'ont', 'am', 'lind', 'amizad', 'am', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'dia', 'deix', 'apavor', 'lug', 'apavor', 'perd', 'outr', 'jog', 'elimin', 'deix', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med', 'med', 'med', 'result', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(palavras)\n",
    "# Agora temos todos os radicais das palavras da nossa base mas podemos perceber que existem radicaias repetidos etnão ainda falta\n",
    "# mostrar apenas uma vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('am', 4),\n",
       " ('dia', 4),\n",
       " ('med', 3),\n",
       " ('nov', 2),\n",
       " ('result', 2),\n",
       " ('test', 2),\n",
       " ('deix', 2),\n",
       " ('apavor', 2),\n",
       " ('admir', 1),\n",
       " ('muit', 1),\n",
       " ('sint', 1),\n",
       " ('complet', 1),\n",
       " ('maravilh', 1),\n",
       " ('sent', 1),\n",
       " ('anim', 1),\n",
       " ('bem', 1),\n",
       " ('hoj', 1),\n",
       " ('bel', 1),\n",
       " ('dirig', 1),\n",
       " ('carr', 1),\n",
       " ('est·', 1),\n",
       " ('bonit', 1),\n",
       " ('cont', 1),\n",
       " ('fiz', 1),\n",
       " ('ont', 1),\n",
       " ('lind', 1),\n",
       " ('amizad', 1),\n",
       " ('vai', 1),\n",
       " ('dur', 1),\n",
       " ('sempr', 1),\n",
       " ('amedront', 1),\n",
       " ('ameac', 1),\n",
       " ('lug', 1),\n",
       " ('perd', 1),\n",
       " ('outr', 1),\n",
       " ('jog', 1),\n",
       " ('elimin', 1),\n",
       " ('pav', 1),\n",
       " ('tom', 1),\n",
       " ('cuid', 1),\n",
       " ('lobisom', 1),\n",
       " ('descobr', 1),\n",
       " ('encrenc', 1),\n",
       " ('trem', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extração das palavras (radicais) livre que existem na base\n",
    "def busca_frequencia(palavras):\n",
    "    palavras = nltk.FreqDist(palavras)\n",
    "    return palavras\n",
    "\n",
    "frequencia = busca_frequencia(palavras)\n",
    "frequencia.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['admir', 'muit', 'sint', 'complet', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'est·', 'bonit', 'cont', 'result', 'test', 'fiz', 'ont', 'lind', 'amizad', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'deix', 'apavor', 'lug', 'perd', 'outr', 'jog', 'elimin', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def busca_palavras_unicas(frequencia):\n",
    "    freq = frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "palavras_unicas = busca_palavras_unicas(frequencia)\n",
    "palavras_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admir': False,\n",
       " 'muit': False,\n",
       " 'sint': False,\n",
       " 'complet': False,\n",
       " 'am': True,\n",
       " 'maravilh': False,\n",
       " 'sent': False,\n",
       " 'anim': False,\n",
       " 'nov': True,\n",
       " 'bem': False,\n",
       " 'hoj': False,\n",
       " 'bel': False,\n",
       " 'dia': True,\n",
       " 'dirig': False,\n",
       " 'carr': False,\n",
       " 'est·': False,\n",
       " 'bonit': False,\n",
       " 'cont': False,\n",
       " 'result': False,\n",
       " 'test': False,\n",
       " 'fiz': False,\n",
       " 'ont': False,\n",
       " 'lind': False,\n",
       " 'amizad': False,\n",
       " 'vai': False,\n",
       " 'dur': False,\n",
       " 'sempr': False,\n",
       " 'amedront': False,\n",
       " 'ameac': False,\n",
       " 'deix': False,\n",
       " 'apavor': False,\n",
       " 'lug': False,\n",
       " 'perd': False,\n",
       " 'outr': False,\n",
       " 'jog': False,\n",
       " 'elimin': False,\n",
       " 'pav': False,\n",
       " 'tom': False,\n",
       " 'cuid': False,\n",
       " 'lobisom': False,\n",
       " 'descobr': False,\n",
       " 'encrenc': False,\n",
       " 'trem': False,\n",
       " 'med': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extrator_palavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavras_unicas:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "\n",
    "caracteristicas_frase = extrator_palavras(['am', 'nov', 'dia'])\n",
    "caracteristicas_frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'admir': True, 'muit': True, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'est·': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ({'admir': False, 'muit': False, 'sint': True, 'complet': True, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'est·': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extração das palavras de todas as frases\n",
    "# o aplly  pega cada uma das frases (frasescomsteming) e vai aplicar a função extrator_palavras e o resultado salva em base_completa\n",
    "base_completa = nltk.classify.apply_features(extrator_palavras, frasescomsteming)\n",
    "base_completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'admir': False, 'muit': False, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'est·': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': True, 'cuid': True, 'lobisom': True, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'medo')\n"
     ]
    }
   ],
   "source": [
    "print(base_completa[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tabela para classificação de sentimentos](./img/tabela_classificcao_sentimento.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# Muito utiliado para tarefas de mineração de texto \n",
    "# Detecção de emoção com texto usando Naive Bayes\n",
    "# Abordagem totalmente probabilística ( Teorema de Bayes )\n",
    "# Exemplos do uso: Filtros de spam (sim ou não), mineração de emoções, separação de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Base de risco de crédito](./img/tabela_risco_credito.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O algoritmo Naive Bayes vai ler a tabela (base de dados) e vai construir uma tabela de probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tabela de probabilidade do Naive Bayes](./img/naive_bayes_probabilidade.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entendendo um pouco a criação da tabela acima. Primeiramente vão preencher essa parte em azul, colocando quantas vezes o risco de crédito alto parece, o risco de crédito moderado aparece e o risco de crédito baixo aparece, vamos completar a informação com o total de casos com os 3 que totaliza 14, assim 6/14 quer dizer que o risco alto aparece 6 vezes no total de 14 registros, o risco moderado aparece apenas 3 no total de 14 registros e o risco baixa aparece 5 no total de 14 registros. \n",
    "\n",
    "Devemos fazer o mesmo para as features, O histórico de crédito bom aparece 5 vezes, o histórico de crédito desconhecido aparece 5x e o histórico de crédito ruim aparece 4. Agora vamos fazer a relação entre risco de crédito Alto e histórico de crédito bom. Dos 5 casos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
